{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3fc0e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.feature_extraction import wav_to_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c03d3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/malakmaher/Documents/GitHub/Emotion-Recognition\n",
      "RAVDESS_ROOT: /Users/malakmaher/Documents/GitHub/Emotion-Recognition/dataset/archive\n",
      "OUTPUT_DIR: /Users/malakmaher/Documents/GitHub/Emotion-Recognition/notebooks/data\n",
      "Total WAV files: 2781\n",
      "Example file: /Users/malakmaher/Documents/GitHub/Emotion-Recognition/dataset/archive/Actor_16/03-01-05-01-02-01-16.wav\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# 1) Find project root: go up from notebooks/ to repo root\n",
    "NOTEBOOK_DIR = Path.cwd()                      # when you open Jupyter from project root\n",
    "if NOTEBOOK_DIR.name == \"notebooks\":\n",
    "    PROJECT_ROOT = NOTEBOOK_DIR.parent\n",
    "else:\n",
    "    # if you're not inside notebooks/, still handle it safely:\n",
    "    # assume repo root is current dir or walk up until \"notebooks\" exists\n",
    "    p = NOTEBOOK_DIR\n",
    "    while p != p.parent and not (p / \"notebooks\").exists():\n",
    "        p = p.parent\n",
    "    PROJECT_ROOT = p\n",
    "\n",
    "# 2) Auto-detect dataset location (supports a couple common layouts)\n",
    "CANDIDATES = [\n",
    "    PROJECT_ROOT / \"dataset\" / \"archive\",\n",
    "    PROJECT_ROOT / \"dataset\",\n",
    "    PROJECT_ROOT / \"data\" / \"ravdess\",\n",
    "    PROJECT_ROOT / \"ravdess\",\n",
    "]\n",
    "\n",
    "RAVDESS_ROOT = next((c for c in CANDIDATES if c.exists()), None)\n",
    "if RAVDESS_ROOT is None:\n",
    "    raise FileNotFoundError(\n",
    "        f\"Could not find RAVDESS dataset folder. Checked: {CANDIDATES}\\n\"\n",
    "        f\"Project root detected as: {PROJECT_ROOT}\"\n",
    "    )\n",
    "\n",
    "# 3) Output directory\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"notebooks\" / \"data\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 4) Collect all wav files (recursive)\n",
    "wav_files = [str(p) for p in RAVDESS_ROOT.rglob(\"*.wav\")]\n",
    "\n",
    "print(\"Project root:\", PROJECT_ROOT)\n",
    "print(\"RAVDESS_ROOT:\", RAVDESS_ROOT)\n",
    "print(\"OUTPUT_DIR:\", OUTPUT_DIR)\n",
    "print(\"Total WAV files:\", len(wav_files))\n",
    "print(\"Example file:\", wav_files[0] if wav_files else \"None\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46f235e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMOTION_LABELS = [\n",
    "    \"neutral\", \"calm\", \"happy\", \"sad\",\n",
    "    \"angry\", \"fearful\", \"disgust\", \"surprised\"\n",
    "]\n",
    "\n",
    "emotion_map = {\n",
    "    1: 0,  # neutral\n",
    "    2: 1,  # calm\n",
    "    3: 2,  # happy\n",
    "    4: 3,  # sad\n",
    "    5: 4,  # angry\n",
    "    6: 5,  # fearful\n",
    "    7: 6,  # disgust\n",
    "    8: 7   # surprised\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4d27040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total WAV files: 2781\n",
      "Example: /Users/malakmaher/Documents/GitHub/Emotion-Recognition/dataset/archive/Actor_16/03-01-05-01-02-01-16.wav\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "wav_files = []\n",
    "for root, _, files in os.walk(str(RAVDESS_ROOT)):\n",
    "    for f in files:\n",
    "        if f.endswith(\".wav\"):\n",
    "            wav_files.append(os.path.join(root, f))\n",
    "\n",
    "print(\"Total WAV files:\", len(wav_files))\n",
    "print(\"Example:\", wav_files[0] if wav_files else \"None\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94020f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2781/2781 [00:36<00:00, 76.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (2781, 128, 128, 2)\n",
      "y shape: (2781,)\n",
      "Saved: X.npy, y.npy, mean_std.json\n"
     ]
    }
   ],
   "source": [
    "# wav_files and emotion_map already defined\n",
    "X, y = [], []\n",
    "\n",
    "for wav_path in tqdm(wav_files):\n",
    "    filename = os.path.basename(wav_path)\n",
    "    emotion_code = int(filename.split(\"-\")[2])\n",
    "    label = emotion_map[emotion_code]\n",
    "\n",
    "    feat = wav_to_features(wav_path)  # (128,128,2)\n",
    "    X.append(feat)\n",
    "    y.append(label)\n",
    "\n",
    "X = np.array(X, dtype=np.float32)  # (N,128,128,2)\n",
    "y = np.array(y, dtype=np.int64)\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "\n",
    "# Dataset-level normalization (per channel)\n",
    "mean = X.mean(axis=(0, 1, 2), keepdims=True)  # (1,1,1,2)\n",
    "std  = X.std(axis=(0, 1, 2), keepdims=True) + 1e-6\n",
    "\n",
    "X = (X - mean) / std\n",
    "\n",
    "# Save mean/std for prediction consistency\n",
    "stats = {\n",
    "    \"mean\": mean.reshape(-1).tolist(),\n",
    "    \"std\": std.reshape(-1).tolist()\n",
    "}\n",
    "\n",
    "os.makedirs(\"notebooks/data\", exist_ok=True)\n",
    "np.save(\"notebooks/data/X.npy\", X)\n",
    "np.save(\"notebooks/data/y.npy\", y)\n",
    "\n",
    "import json\n",
    "with open(\"notebooks/data/mean_std.json\", \"w\") as f:\n",
    "    json.dump(stats, f)\n",
    "\n",
    "print(\"Saved: X.npy, y.npy, mean_std.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emotion-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
